{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from multiprocessing import Process\n",
    "from empath import Empath\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textblob\n",
    "import spacy\n",
    "import time\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "prog = re.compile(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z' \\t])|(\\w+:\\/\\/\\S+)\")\n",
    "prog2 = re.compile(\" +\")\n",
    "lexicon = Empath()\n",
    "empath_cols = [\"{0}_empath\".format(v) for v in lexicon.cats.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatization(x, nlp):\n",
    "    tweets = \" \".join(list(x.values))\n",
    "    letters_only = prog.sub(\" \", tweets)\n",
    "    lemmatized = []\n",
    "    for token1 in nlp(letters_only):\n",
    "        if token1.lemma_ != \"-PRON-\" and token1 not in stopWords:\n",
    "            lemmatized.append(token1.lemma_)\n",
    "        else:\n",
    "            lemmatized.append(token1.text)\n",
    "    final = prog2.sub(\" \", \" \".join(lemmatized))\n",
    "    return final\n",
    "\n",
    "\n",
    "def empath_analysis(x):\n",
    "    val = lexicon.analyze(x, normalize=True)\n",
    "    if val is None:\n",
    "        return lexicon.analyze(x)\n",
    "    else:\n",
    "        return val\n",
    "#print(lemmatization(x,nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processing(vals, columns, iterv):\n",
    "    users = pd.DataFrame(vals)\n",
    "    users = users[columns]\n",
    "\n",
    "    print(\"{0}-------------\".format(iterv))\n",
    "\n",
    "    # PRE-PROCESSING\n",
    "\n",
    "    users_text = users.groupby([\"uid\"])[\"tweet\"].apply(lambda x: lemmatization(x, nlp)).reset_index()\n",
    "    print(\"{0}-------------PRE-PROCESSING\".format(iterv))\n",
    "\n",
    "    # SENTIMENT ANALYSIS\n",
    "\n",
    "    sentiment_arr = np.array(list(users_text[\"tweet\"].apply(lambda x: textblob.TextBlob(str(x)).sentiment).values))\n",
    "    sentiment_cols = [\"sentiment\", \"subjectivity\"]\n",
    "    df_sentiment = pd.DataFrame(sentiment_arr, columns=sentiment_cols, index=users_text.uid.values)\n",
    "    print(\"{0}-------------SENTIMENT\".format(iterv))\n",
    "\n",
    "    # EMPATH ANALYSIS\n",
    "\n",
    "    lexicon_arr = np.array(list(users_text[\"tweet\"].apply(lambda x: empath_analysis(x)).values))\n",
    "    df_empath = pd.DataFrame.from_records(index=users_text.uid.values, data=lexicon_arr)\n",
    "    df_empath.columns = empath_cols\n",
    "    print(\"{0}-------------EMPATH\".format(iterv))\n",
    "\n",
    "    # MERGE TO SINGLE\n",
    "\n",
    "    df = pd.DataFrame(pd.concat([df_empath, df_sentiment], axis=1))\n",
    "    #df.set_index(\"uid\", inplace=True)\n",
    "    df.to_csv(\"G:\\\\sufe\\\\mental illness\\\\Dataset\\\\labeled\\\\negative\\\\data\\\\feature\\\\users_content_{0}.csv\".format(iterv))\n",
    "    print(\"-------------{0}\".format(iterv))\n",
    "#print(data_df.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-------------\n",
      "0-------------PRE-PROCESSING\n",
      "0-------------SENTIMENT\n",
      "0-------------EMPATH\n",
      "-------------0\n",
      "88.48106098175049\n",
      "1-------------\n",
      "1-------------PRE-PROCESSING\n",
      "1-------------SENTIMENT\n",
      "1-------------EMPATH\n",
      "-------------1\n",
      "140.73204946517944\n",
      "2-------------\n",
      "2-------------PRE-PROCESSING\n",
      "2-------------SENTIMENT\n",
      "2-------------EMPATH\n",
      "-------------2\n",
      "104.23796224594116\n",
      "3-------------\n",
      "3-------------PRE-PROCESSING\n",
      "3-------------SENTIMENT\n",
      "3-------------EMPATH\n",
      "-------------3\n",
      "180.86334490776062\n",
      "4-------------\n",
      "4-------------PRE-PROCESSING\n",
      "4-------------SENTIMENT\n",
      "4-------------EMPATH\n",
      "-------------4\n",
      "134.61669969558716\n",
      "5-------------\n",
      "5-------------PRE-PROCESSING\n",
      "5-------------SENTIMENT\n",
      "5-------------EMPATH\n",
      "-------------5\n",
      "327.53973412513733\n",
      "6-------------\n",
      "6-------------PRE-PROCESSING\n",
      "6-------------SENTIMENT\n",
      "6-------------EMPATH\n",
      "-------------6\n",
      "185.84062910079956\n",
      "7-------------\n",
      "7-------------PRE-PROCESSING\n",
      "7-------------SENTIMENT\n",
      "7-------------EMPATH\n",
      "-------------7\n",
      "615.8762259483337\n",
      "8-------------\n",
      "8-------------PRE-PROCESSING\n",
      "8-------------SENTIMENT\n",
      "8-------------EMPATH\n",
      "-------------8\n",
      "182.94446349143982\n",
      "9-------------\n",
      "9-------------PRE-PROCESSING\n",
      "9-------------SENTIMENT\n",
      "9-------------EMPATH\n",
      "-------------9\n",
      "145.2253062725067\n",
      "10-------------\n",
      "10-------------PRE-PROCESSING\n",
      "10-------------SENTIMENT\n",
      "10-------------EMPATH\n",
      "-------------10\n",
      "186.72067999839783\n",
      "11-------------\n",
      "11-------------PRE-PROCESSING\n",
      "11-------------SENTIMENT\n",
      "11-------------EMPATH\n",
      "-------------11\n",
      "166.86054372787476\n",
      "12-------------\n",
      "12-------------PRE-PROCESSING\n",
      "12-------------SENTIMENT\n",
      "12-------------EMPATH\n",
      "-------------12\n",
      "147.40243101119995\n",
      "13-------------\n",
      "13-------------PRE-PROCESSING\n",
      "13-------------SENTIMENT\n",
      "13-------------EMPATH\n",
      "-------------13\n",
      "119.9568612575531\n",
      "14-------------\n",
      "14-------------PRE-PROCESSING\n",
      "14-------------SENTIMENT\n",
      "14-------------EMPATH\n",
      "-------------14\n",
      "192.58801531791687\n",
      "15-------------\n",
      "15-------------PRE-PROCESSING\n",
      "15-------------SENTIMENT\n",
      "15-------------EMPATH\n",
      "-------------15\n",
      "167.6755907535553\n",
      "16-------------\n",
      "16-------------PRE-PROCESSING\n",
      "16-------------SENTIMENT\n",
      "16-------------EMPATH\n",
      "-------------16\n",
      "153.08475589752197\n",
      "17-------------\n",
      "17-------------PRE-PROCESSING\n",
      "17-------------SENTIMENT\n",
      "17-------------EMPATH\n",
      "-------------17\n",
      "170.88277387619019\n",
      "18-------------\n",
      "18-------------PRE-PROCESSING\n",
      "18-------------SENTIMENT\n",
      "18-------------EMPATH\n",
      "-------------18\n",
      "112.94546031951904\n",
      "19-------------\n",
      "19-------------PRE-PROCESSING\n",
      "19-------------SENTIMENT\n",
      "19-------------EMPATH\n",
      "-------------19\n",
      "146.19236159324646\n",
      "20-------------\n",
      "20-------------PRE-PROCESSING\n",
      "20-------------SENTIMENT\n",
      "20-------------EMPATH\n",
      "-------------20\n",
      "125.73219132423401\n",
      "21-------------\n",
      "21-------------PRE-PROCESSING\n",
      "21-------------SENTIMENT\n",
      "21-------------EMPATH\n",
      "-------------21\n",
      "137.00183582305908\n",
      "22-------------\n",
      "22-------------PRE-PROCESSING\n",
      "22-------------SENTIMENT\n",
      "22-------------EMPATH\n",
      "-------------22\n",
      "60.53046226501465\n",
      "23-------------\n",
      "23-------------PRE-PROCESSING\n",
      "23-------------SENTIMENT\n",
      "23-------------EMPATH\n",
      "-------------23\n",
      "174.18196272850037\n",
      "24-------------\n",
      "24-------------PRE-PROCESSING\n",
      "24-------------SENTIMENT\n",
      "24-------------EMPATH\n",
      "-------------24\n",
      "159.66813254356384\n",
      "25-------------\n",
      "25-------------PRE-PROCESSING\n",
      "25-------------SENTIMENT\n",
      "25-------------EMPATH\n",
      "-------------25\n",
      "152.2977111339569\n",
      "26-------------\n",
      "26-------------PRE-PROCESSING\n",
      "26-------------SENTIMENT\n",
      "26-------------EMPATH\n",
      "-------------26\n",
      "119.0548095703125\n",
      "27-------------\n",
      "27-------------PRE-PROCESSING\n",
      "27-------------SENTIMENT\n",
      "27-------------EMPATH\n",
      "-------------27\n",
      "164.00738072395325\n",
      "28-------------\n",
      "28-------------PRE-PROCESSING\n",
      "28-------------SENTIMENT\n",
      "28-------------EMPATH\n",
      "-------------28\n",
      "131.51952266693115\n",
      "29-------------\n",
      "29-------------PRE-PROCESSING\n",
      "29-------------SENTIMENT\n",
      "29-------------EMPATH\n",
      "-------------29\n",
      "146.24336457252502\n",
      "30-------------\n",
      "30-------------PRE-PROCESSING\n",
      "30-------------SENTIMENT\n",
      "30-------------EMPATH\n",
      "-------------30\n",
      "163.06332659721375\n",
      "31-------------\n",
      "31-------------PRE-PROCESSING\n",
      "31-------------SENTIMENT\n",
      "31-------------EMPATH\n",
      "-------------31\n",
      "152.55272555351257\n",
      "32-------------\n",
      "32-------------PRE-PROCESSING\n",
      "32-------------SENTIMENT\n",
      "32-------------EMPATH\n",
      "-------------32\n",
      "169.2376799583435\n",
      "33-------------\n",
      "33-------------PRE-PROCESSING\n",
      "33-------------SENTIMENT\n",
      "33-------------EMPATH\n",
      "-------------33\n",
      "209.2579689025879\n",
      "34-------------\n",
      "34-------------PRE-PROCESSING\n",
      "34-------------SENTIMENT\n",
      "34-------------EMPATH\n",
      "-------------34\n",
      "178.90223264694214\n",
      "35-------------\n",
      "35-------------PRE-PROCESSING\n",
      "35-------------SENTIMENT\n",
      "35-------------EMPATH\n",
      "-------------35\n",
      "171.0137813091278\n",
      "36-------------\n",
      "36-------------PRE-PROCESSING\n",
      "36-------------SENTIMENT\n",
      "36-------------EMPATH\n",
      "-------------36\n",
      "168.42263317108154\n",
      "37-------------\n",
      "37-------------PRE-PROCESSING\n",
      "37-------------SENTIMENT\n",
      "37-------------EMPATH\n",
      "-------------37\n",
      "180.82434248924255\n",
      "38-------------\n",
      "38-------------PRE-PROCESSING\n",
      "38-------------SENTIMENT\n",
      "38-------------EMPATH\n",
      "-------------38\n",
      "173.73993730545044\n",
      "39-------------\n",
      "39-------------PRE-PROCESSING\n",
      "39-------------SENTIMENT\n",
      "39-------------EMPATH\n",
      "-------------39\n",
      "144.05723977088928\n",
      "40-------------\n",
      "40-------------PRE-PROCESSING\n",
      "40-------------SENTIMENT\n",
      "40-------------EMPATH\n",
      "-------------40\n",
      "187.96775126457214\n",
      "41-------------\n",
      "41-------------PRE-PROCESSING\n",
      "41-------------SENTIMENT\n",
      "41-------------EMPATH\n",
      "-------------41\n",
      "143.88723015785217\n",
      "42-------------\n",
      "42-------------PRE-PROCESSING\n",
      "42-------------SENTIMENT\n",
      "42-------------EMPATH\n",
      "-------------42\n",
      "194.88414669036865\n",
      "43-------------\n",
      "43-------------PRE-PROCESSING\n",
      "43-------------SENTIMENT\n",
      "43-------------EMPATH\n",
      "-------------43\n",
      "189.23082327842712\n",
      "44-------------\n",
      "44-------------PRE-PROCESSING\n",
      "44-------------SENTIMENT\n",
      "44-------------EMPATH\n",
      "-------------44\n",
      "271.8035464286804\n",
      "45-------------\n",
      "45-------------PRE-PROCESSING\n",
      "45-------------SENTIMENT\n",
      "45-------------EMPATH\n",
      "-------------45\n",
      "250.00129914283752\n",
      "46-------------\n",
      "46-------------PRE-PROCESSING\n",
      "46-------------SENTIMENT\n",
      "46-------------EMPATH\n",
      "-------------46\n",
      "252.3074312210083\n",
      "47-------------\n",
      "47-------------PRE-PROCESSING\n",
      "47-------------SENTIMENT\n",
      "47-------------EMPATH\n",
      "-------------47\n",
      "207.89589095115662\n",
      "48-------------\n",
      "48-------------PRE-PROCESSING\n",
      "48-------------SENTIMENT\n",
      "48-------------EMPATH\n",
      "-------------48\n",
      "138.9169454574585\n",
      "49-------------\n",
      "49-------------PRE-PROCESSING\n",
      "49-------------SENTIMENT\n",
      "49-------------EMPATH\n",
      "-------------49\n",
      "239.63070583343506\n",
      "50-------------\n",
      "50-------------PRE-PROCESSING\n",
      "50-------------SENTIMENT\n",
      "50-------------EMPATH\n",
      "-------------50\n",
      "173.88594579696655\n",
      "51-------------\n",
      "51-------------PRE-PROCESSING\n",
      "51-------------SENTIMENT\n",
      "51-------------EMPATH\n",
      "-------------51\n",
      "170.81377029418945\n",
      "52-------------\n",
      "52-------------PRE-PROCESSING\n",
      "52-------------SENTIMENT\n",
      "52-------------EMPATH\n",
      "-------------52\n",
      "191.07992935180664\n",
      "53-------------\n",
      "53-------------PRE-PROCESSING\n",
      "53-------------SENTIMENT\n",
      "53-------------EMPATH\n",
      "-------------53\n",
      "103.26990675926208\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "N=54\n",
    "filepath='G:\\\\sufe\\\\mental illness\\\\Dataset\\\\labeled\\\\negative\\\\data\\\\'\n",
    "cols = ['favorite_count', 'favorited', 'id', 'in_reply_to_status_id', 'lang', 'retweet_count', 'retweeted', 'time', 'tweet', 'uid']\n",
    "for i in range(N):\n",
    "    filename = filepath + 'negative_tweet{0}'.format(i)+'.csv'\n",
    "    #data_df = pd.read_csv(filename)\n",
    "    #data_df.columns=['favorite_count', 'favorited', 'id', 'in_reply_to_status_id', 'lang', 'retweet_count', 'retweeted', 'time', 'tweet', 'uid']\n",
    "    #data_df.to_csv(filename,index=False)\n",
    "    f =open(filename,'r',encoding='utf-8')\n",
    "    csv_dict_reader = csv.DictReader(f)\n",
    "    v=[]\n",
    "    for line in csv_dict_reader:\n",
    "        #提取特征\n",
    "        v.append(line)\n",
    "    s = time.time()\n",
    "    processing(v, cols, i)\n",
    "    print(time.time() - s)        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
